using System.Text;
using System.Text.Json;
using Janet.DubCore.Models;

namespace Janet.DubCore.Services;

public class IntentService : IIntentService
{
    private readonly IAppConfigService _configService;
    private readonly ILoggingService _loggingService;

    private static readonly HttpClient client = new HttpClient();
    private readonly string _ollamaApiUrl;
    private readonly string _modelName;

    public IntentService(IAppConfigService configService, ILoggingService loggingService)
    {
        _configService = configService;
        _loggingService = loggingService;

        // Ensure the URL from config points to the /api/generate endpoint
        var baseUrl = _configService.Settings.Ollama.BaseUrl.TrimEnd('/');
        _ollamaApiUrl = $"{baseUrl}/api/generate";
        _modelName = _configService.Settings.Ollama.IntentModelName;

        _loggingService.LogInfo($"IntentService initialized [{_modelName}] with Ollama API URL: " + _ollamaApiUrl);
    }

    public Task<ChatMessage> ProcessMessage(ChatMessage message)
    {
        
        _loggingService.LogInfo($"Processing intent for message: {message.Message}");
        message.Intent = GetIntentAndEntitiesAsJsonAsync(message.Message).GetAwaiter().GetResult();
        return Task.FromResult(message);
    }

        /// <summary>
    /// Sends a user query to the Ollama API to extract intent and entities as a JSON object.
    /// The method constructs a system prompt to guide the model's response format, sends the request,
    /// and parses the model's output into an <see cref="OllamaIntent"/> instance.
    /// Handles various error scenarios, including empty queries, API failures, and unexpected exceptions.
    /// </summary>
    /// <param name="userQuery">The user's input query to analyze for intent and entities.</param>
    /// <returns>
    /// An <see cref="OllamaIntent"/> object containing the extracted intent and entities,
    /// or an error intent with details if the operation fails.
    /// </returns>
    /// <exception cref="HttpRequestException">
    /// Thrown when there is a network-related error communicating with the Ollama API.
    /// </exception>
    /// <exception cref="Exception">
    /// Thrown when an unexpected error occurs, such as serialization issues.
    /// </exception>
    public async Task<OllamaIntent> GetIntentAndEntitiesAsJsonAsync(string userQuery)
    {
        if (string.IsNullOrWhiteSpace(userQuery))
        {
            return new OllamaIntent { intent = "error", entities = { { "message", "Query cannot be empty." } } };
        }

        // This system prompt guides the model on its role and the structure of the JSON it should produce.
        const string systemPrompt = @"You are an expert at extracting user intent and entities from a given query. 
Your response MUST be a single, well-formed JSON object and nothing else.
The JSON object should have two top-level properties:
1. 'intent': A string representing the user's primary goal (e.g., 'set_timer', 'find_weather'). Use snake_case for the intent name.
2. 'entities': An object containing key-value pairs of extracted information (e.g., {'location': 'Paris', 'date': 'tomorrow'}).
Do not add any explanations, comments, or markdown formatting around the JSON.";

        // The request payload for the Ollama API.
        var requestPayload = new OllamaRequest
        {
            Model = _modelName,
            System = systemPrompt,
            Prompt = $"User Query: \"{userQuery}\"",
            Format = "json", // Enables Ollama's JSON mode.
            Stream = false
        };

        try
        {
            // Serialize the payload and create the HTTP request content.
            string jsonPayload = JsonSerializer.Serialize(requestPayload);
            var content = new StringContent(jsonPayload, Encoding.UTF8, "application/json");

            // Send the POST request to the Ollama API.
            HttpResponseMessage response = await client.PostAsync(_ollamaApiUrl, content);

            // Read the response content regardless of status code.
            string responseBody = await response.Content.ReadAsStringAsync();

            if (response.IsSuccessStatusCode)
            {
                // The model's output is nested within the API response.
                var ollamaResponse = JsonSerializer.Deserialize<OllamaResponse>(responseBody);

                if (ollamaResponse != null && !string.IsNullOrWhiteSpace(ollamaResponse.Response))
                {

                    var intent = JsonSerializer.Deserialize<OllamaIntent>(ollamaResponse.Response) ?? new OllamaIntent { intent = "error", entities = { { "message", "Failed to parse intent from model response." } } };
                    //_loggingService.LogDebug("Ollama raw response:", responseBody);
                    // The 'Response' property contains the JSON string generated by the model.
                    return intent;
                }
                else
                {
                    _loggingService.LogWarning("Ollama response is null or empty.");
                    return new OllamaIntent { intent = "error", entities = { { "message", "Model response is null or empty." } } };
                }
            }
            else
            {
                _loggingService.LogError($"Ollama API call failed with status code: {(int)response.StatusCode}");
                _loggingService.LogDebug("Ollama error response:", responseBody);
                // Handle non-successful HTTP status codes.
                return new OllamaIntent { intent = "error", entities = { { "message", "Failed to call Ollama API." }, { "status_code", ((int)response.StatusCode).ToString() }, { "details", responseBody } } };
            }
        }
        catch (HttpRequestException e)
        {
            _loggingService.LogError("HTTP request to Ollama API failed: " + e.Message);
            _loggingService.LogDebug("Ollama error response:", e.ToString());
            // Handle network-related errors (e.g., Ollama server is not running).
            return new OllamaIntent
            {
                intent = "error",
                entities = { { "message", "Could not connect to the Ollama service. Please ensure it is running." }, { "details", e.Message } }
            };
        }
        catch (Exception e)
        {
            // Handle other potential exceptions, such as serialization errors.
            _loggingService.LogError("An unexpected error occurred: " + e.Message);
            _loggingService.LogDebug("Ollama error response:", e.ToString());
            return new OllamaIntent
            {
                intent = "error",
                entities = { { "message", "An unexpected error occurred." }, { "details", e.Message } }
            };
        }
    }
}